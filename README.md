# PointNet-Based Pedicle Landmark and Segmentation Pipeline

This repository provides a full pipeline for point cloud-based vertebral landmark detection and segmentation using a PointNet-based neural network architecture. It includes preprocessing, augmentation, training, and evaluation of a model tailored to spinal anatomy datasets.

---

## ğŸ“ Repository Structure

â”œâ”€â”€ dataset.py              # Custom PyTorch Dataset class for loading NPZ point clouds
â”œâ”€â”€ model.py                # PointNet model definitions (segmentation, classification)
â”œâ”€â”€ trainer.py              # Training script for segmentation using PointNet
â”œâ”€â”€ preprocessing.py        # Mesh augmentation, landmark labeling, noise addition
â”œâ”€â”€ folding.py              # Generates train/val/test splits from NPZ files
â”œâ”€â”€ data/                   # Your structured dataset directory (STLs + NPZ files)
â”‚   â”œâ”€â”€ fold_1/
â”‚   â”‚   â”œâ”€â”€ train_data.json
â”‚   â”‚   â”œâ”€â”€ val_data.json
â”‚   â”‚   â”œâ”€â”€ test_data.json

---

## ğŸ§° Requirements

Install dependencies with:

```bash
pip install torch numpy pyvista scikit-learn tqdm

Tested with:
	â€¢	Python 3.8+
	â€¢	PyTorch â‰¥ 1.11
	â€¢	PyVista for STL mesh loading and manipulation

â¸»

ğŸš€ Usage

1. Preprocess STL Meshes and Landmarks

Prepare your .stl meshes and .npz landmark files, then run:

python preprocessing.py

This will:
	â€¢	Augment meshes (if "USR" in filename)
	â€¢	Add Gaussian noise to vertices
	â€¢	Compute label heatmaps
	â€¢	Save .npz point clouds and augmented .stl files

2. Create Dataset Splits

python folding.py

Creates:
	â€¢	train_data.json
	â€¢	val_data.json
	â€¢	test_data.json
inside fold_1/, ready for training.

3. Train the Model

python trainer.py --dataset path/to/dataset --class_choice spine

Optional flags:
	â€¢	--feature_transform â€” enables feature transform regularization
	â€¢	--model path/to/model.pth â€” resumes training from a checkpoint

â¸»

ğŸ“¦ NPZ File Format

Each .npz file contains:
	â€¢	vertices: (N, 3) point cloud
	â€¢	labels: (N,) semantic class labels (0 = background, 1â€“4 = landmark types)
	â€¢	landmarks: (4, 3) landmark coordinates

â¸»

ğŸ“ˆ Output

After training:
	â€¢	Model checkpoints saved to seg_noisy/
	â€¢	Training/test accuracy printed per epoch
	â€¢	Final mIoU score reported at end





